---
title: "Initial Analysis"
author: "Juliano Palacios-Abrantes"
date: '2019-02-04'
output: html_document
editor_options: 
  chunk_output_type: console
---


```{r setup, eval = T, echo=F, warning=F,message=F, results='hide'}

#### READ ME !!! ####
# Run this chunk before knit so you make sure you have all pkgs installed in R

ipak <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg)) 
    install.packages(new.pkg, dependencies = TRUE,repos = "http://cran.us.r-project.org")
  sapply(pkg, require, character.only = TRUE)
}


#### Library ####
packages <- c(
  "readxl", # Read dataframe
  "data.table", # Read dataframe (Fast!)
  "dplyr", # Data manipulation
  "tidyr", # Data manipulation
  "ggplot2", #Nice grpahs and spatial analysis
  "wesanderson",
  "circlize", # For circular plot
  # "cowplot",
  # "rgdal",
  # "RColorBrewer",
  # "knitr",
  # "kableExtra",
  # "ggrepel",
  # "gridExtra",
  # "ggmap",
  # "rgeos",
  # "stringr",
  # "stringer",
  "spdep", # for poly2nb
  "sf", #Spatial analysis 
  "sp", #Spatial analysis 
  "purrr",#Spatial analysis
  "rgdal", #Spatial analysis
  "tools", #Spatial analysis 
  # "png", # For reading plots in chunk codes
  # "grid" # For reading plots in chunk codes
  "parallel" # for parallelization
)

ipak(packages)

ggtheme_map <- function(base_size = 9, Region = "NA") {
  
  theme(text             = element_text(#family = "Helvetica",
    color = "gray30", size = base_size),
    plot.title       = element_text(size = rel(1.25), hjust = 0, face = "bold"),
    panel.background = element_blank(),
    panel.border     = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(color = "transparent"),
    strip.background =element_rect(fill = "transparent"),
    strip.text.x = element_text(size = 18, colour = "black",face= "bold.italic", angle = 0),
    axis.line        = element_blank(), # element_line(colour = "grey30", size = .5))
    axis.ticks       = element_blank(),
    axis.text        = element_blank(),
    axis.title       = element_blank(),
    legend.key       = element_rect(colour = NA, fill = NA, size = 4),
    legend.position = "bottom",
    legend.key.width =unit(6,"line")
  )
}

#### Set paths for computer ####


# Set paths depending on machine Beast (jepa88), "carmelia" or Hall1000
if(Sys.info()[7] == "jepa88"){
  Data_Path <- "Z:/JULIANO_NEYMAR/FishForVisa/"
  Path <- paste(Data_Path,"Results/",sep = "")
  }
if(Sys.info()[7] == "carmelia"){
  Data_Path <- "~/GitHub/FishForVisa/Temporal_Data/"
  Path <- paste(Data_Path,sep = "")
}
if(Sys.info()[7] == "hall1000"){
  Data_Path <- "/Volumes/DATA/JULIANO_NEYMAR/FishForVisa/"
  Path <- paste(Data_Path,"Results/",sep = "")
}

# Path for saving Results

# If path exists overrite it, otherwise creats a new path for that year
if(file.exists(Path) == TRUE){
  Results_Path = Path
}else{
  dir.create(Path)
  Results_Path = Path
}

### Message for my brain

print("_____________________ WARNING DO NOT FORGET TO PULL/PUSH BEFORE YOU START_____________________")

```


# Methods

These are the methods to follow:

1. Determine which countries have neighboring EEZs  
  1.1. For this we used the Marine regions EEZ maps (We have to change this because it does not discriminate by oceans and we need this) and a routine to identify neighboring polygons,
  1.2. Then we match the DBEM spatial information (e.g. INDEX within EEZ and coordinates) with the neighboring data
2. Overlap distribution maps with neighbors data  
  2.1. For each species we merged the DBEM_Neighbors data with their known distribution (Gab's data)  
3. Determine transboundary if:  
  3.1. Species is present in both neighboring EEZs by INDEX  

Alternatively, we could create a "confidence level" based on a ratio, i.e;
- How many grid cells of both the EEZs is the species present on. A species that covers all cells would have 100% but a species that covers, lets say, all of EEZ1 but only half of EEZ2 would be 75%.  
- Another option is to have the index based on the species distribution. That is to say, what proportion of the total species distribution actually falls within both EEZs....


### Current issues

- How to distinguish between North and South? Example of Brazil, Uruguay and French Guyana

## Data

```{r Speceis_List_For_Data, eval = F, echo = T}

# Get the DBEM list of species to extract from other modesl
#GFDL
DBEM_species_G <- data_frame(TaxonKey = list.files("/Volumes/DATA/DATA/DBEM/GFDL26F1"))
#IPSL
DBEM_species_I <- data_frame(TaxonKey = list.files("/Volumes/DATA/DATA/DBEM/IPSL26F1"))
#MPI
DBEM_species_M <- data_frame(TaxonKey = list.files("/Volumes/DATA/DATA/DBEM/MPI26F1"))


# Merge the, and save to send to gabs

DBEM_Species_List <- DBEM_species_I %>% 
  bind_rows(DBEM_species_G,
            DBEM_species_M) %>% 
  group_by(TaxonKey) %>% 
  summarise() %>% 
  filter(str_detect(TaxonKey, "^6"))


# Include species name, as well... 

exploited_species <- read.csv("/Volumes/DATA/PROJECTION exploited species ENM/exploited_species_list.csv")

DBEM_Species_List <- DBEM_Species_List %>% 
  left_join(exploited_species,
            by ="TaxonKey")


# write.csv(DBEM_Species_List,
#           "DBEM_Species_List.csv",
#           row.names = F)

### Check Gabs Data ####

# Does all data have the same number of files?

# SAU <- length(list.files("/Volumes/DATA/JULIANO_NEYMAR/FishForVisa/Distribution_Data/SAU_Distribution/"))
# ENM <- length(list.files("/Volumes/DATA/JULIANO_NEYMAR/FishForVisa/Distribution_Data/ENM/"))
# Occ <- length(list.files("/Volumes/DATA/JULIANO_NEYMAR/FishForVisa/Distribution_Data/Occurence/"))

####### Yes they do! ####

#### List of species we have data for...

# Removes everything before the number
Step_One <- gsub(".*_","",list.files("/Volumes/DATA/JULIANO_NEYMAR/FishForVisa/Distribution_Data/SAU_Distribution/"))

# Species List
Species_List <- gsub("\\..*","",Step_One)


# Get All SAU species for the final analysis



```

## Sub Routine Estimating Neighbords

### Functions `EstNeighbors`

This function determines what EEZs are neighbors and returns a data.frame of it

```{r funEstNeighbors, eval = F, echo=T}
# Determine which countries are neighbors

# Method adopted from Adrew Heiss
# https://gist.github.com/andrewheiss/926b9d60a26e29f6bf32

EstNeighbors <- function(Shapefile){
  
  # Get the list using the poly2nb function
  
  Neighbor_List <- poly2nb(Shapefile)
  
  # Convert te nb data to a Matrix of crossing references
  Neighbor_Matrix <- nb2mat(Neighbor_List,
                            style="B", 
                            zero.policy=TRUE)
  
  # Rename the matrix axis
  colnames(Neighbor_Matrix) <- rownames(Neighbor_Matrix)
  
  
  # Get the names of the countries for identifying them
  Country_Names <- tibble(id = row.names(Shapefile@data),
                              Country_Territory = as.character(Shapefile@data$Name),
                              Neighbor_Territory = Country_Territory,
                              EEZID = Shapefile@data$EEZID # specific of SAU sf
                              )
  
  # Clean up and transform the neighbor matrix
  Neighbors <- as.data.frame(Neighbor_Matrix) %>%
    mutate(country = row.names(.)) %>%  # Convert row names to actual column
    gather(neighbor, present, -country) %>%  # Convert to long
    filter(present == 1) %>%  # Only look at cells with a match
    # Add country names
    left_join(select(Country_Names,
                     -Neighbor_Territory), by=c("country" = "id")) %>%
    left_join(select(Country_Names, 
                     -Country_Territory), by=c("neighbor" = "id")) %>% 
    select(EEZID = EEZID.x,Country_Territory,Neighbor_Territory) # select final column
 
    # Merge them with SAU data
  
  DBEM_Neighbors_Data <- EEZIDs_List %>% 
  left_join(EEZ_CellID, 
            by = "EEZID") %>% # Asign EEZ id to each country
  left_join(Neighbors, 
            by = "EEZID") %>% # Include all neighboring countries 
  filter(Neighbor_Territory != "NA") %>% 
  left_join(Coor,
            by = "INDEX") # Inclu
  
  return(DBEM_Neighbors_Data)
   
}


### Test function

# Subset data for testing function
# SAU_Regions <- as.data.frame(unique(World_EEZs$Name))

# Test_Countries <-c("Mexico (Atlantic)","Mexico (Pacific)","Guatemala (Caribbean)","Guatemala (Pacific)","Belize")
# Test <- World_EEZs[World_EEZs@data$Name %in% Test_Countries, ]

# Running function
# getNeighbors(Test)

#### Works beautifully! 

```

## Sub Routine

```{r Neighbords_Control_Pannel, eval = F, echo = F}

#### Load Data Needed ####

# Spatial analysis for Countries boundaries from marine regions ####

###_______________________________Read Me_____________________________________________#
#### Data License and references ###
# Marine Regionsâ€™ data is licensed under CC-By-NC-SA (https://creativecommons.org/licenses/by-nc-sa/4.0/).
# Flanders Marine Institute (2018). Maritime Boundaries Geodatabase: Maritime Boundaries and Exclusive Economic Zones (200NM), version 10. Available online at http://www.marineregions.org/. https://doi.org/10.14284/312

#### Using the SAU shapefile that contains EEZ per ocean (E.G. Mexico Pacific and Mexico Atlantic)
###________________________________________________________________________________#

# The path
path_world <- paste(Data_Path,"Spatial_Data/SAU_Shapefile",sep="")
#The File
fnam_world <- "SAUEEZ_July2015.shp"
#Load it!

World_EEZs <- readOGR(dsn = path_world,
                      layer =file_path_sans_ext(fnam_world))

#### Grid cell information ####

# List of DBEM INDEX within the EEZ 
#Data provided by Vicki Lam

EEZIDs_List <- read_excel(paste(Data_Path,"Spatial_Data/V_Lam/Updated_EEZList_17June2016.xlsx",sep=""))
EEZ_CellID <- read_excel(paste(Data_Path,"Spatial_Data/V_Lam/EEZ_CellID.xlsx",sep=""))

colnames(EEZ_CellID) <- c("EEZID","INDEX")

# DBEM Coordinate system
Coor <- fread(paste(Data_Path,"Spatial_Data/Lon_Lat_DBEM.txt",sep=""),header = FALSE)
colnames(Coor) <- c("INDEX","Longitude","Latitude")


# Run Function (Ran and saved May 27 2019 at 6pm)
 system.time(
  Neighbor_List <- EstNeighbors(World_EEZs)
 )
# 8203.05    0.25 8204.51 (around 2 hours 30 min)

write.csv(Neighbor_List,
          paste(Data_Path,"Spatial_Data/Neighbor_List.csv", sep =""),
          row.names = F)




####_________________________________________ TESTING PERIOD_________________________________________####
# I'm substetting central america to do the whole analysis (smaller EEZs = faster computation) once I have figure out things I'll run for all

### Data
# For now using only the subdata

## Spatial Test Data
# SAU_Regions <- as.data.frame(unique(World_EEZs$Name))

# Test_Countries <-c("Guatemala (Caribbean)","Guatemala (Pacific)","Belize","Honduras (Pacific)","El Salvador","Costa Rica (Pacific)","Costa Rica (Caribbean)", "Panama (Caribbean)", "Panama (Pacific)")

# Test <- World_EEZs[World_EEZs@data$Name %in% Test_Countries, ]

```


### Function `GetSppDist`

This function Read in species distribution from the observation data, ESM models and SAU data, still missing DBEM

```{r GetSppDist, eval = T, echo = T}

#### The function
# NOTES
# For now we're using only the last 10 years average, basicaaly if the species has been fished in any of these years, its considered present

GetSppDist=function(Spp,Model,Coord){
  
  Distpath <- paste(Data_Path,"Distribution_Data/",sep="")
  INDEX = seq(1,259200,1)
  # INDEX <- Coordinates$INDEX
  
  # SAU Distributions
  if(Model == "SAU_D"){
    File_Name <- paste("SAU_Distribution/DIST_GOOD_SP_")
  }
  
  # SAU Catch
  if(Model == "SAU_C"){
    File_Name <- paste("SAU_data_per_species/CATCH_SP_")
  }
  
  # Occurence
  if(Model == "Occ"){
    File_Name <- paste("Occurence/OCCURENCE_JULIANO_")
  }
  
  # ENM Model
  if(Model == "ENM"){
    File_Name <- paste("ENM/ENM_JULIANO_")
  }
  
  # DBEM Data
  # if(Model == "DBEM"){
  #   Distpath <- "/Volumes/DATA/JULIANO_NEYMAR/PristineSeasData
  #   Final_Path <- "ENM"
  #   File_Name <- paste("ENM_JULIANO",Spp,".mat",sep="")
  # }
  
  if(Model == "All"){
    
    Models_List <- c(paste(Distpath,"SAU_Distribution/DIST_GOOD_SP_",Spp,".mat",sep =""),
                     paste(Distpath,"Occurence/OCCURENCE_JULIANO_",Spp,".mat",sep=""),
                     paste(Distpath,"ENM/ENM_JULIANO_",Spp,".mat",sep="")
                     )
    
    # Jumps species not modeled. NOTE: We only need one as ENM, Occ and SAU Dis have all the same 939 spp
    if(file.exists(Models_List[1])){
    
    Load <- lapply(Models_List, FUN=R.matlab::readMat, na.strings=0)
     
    sppdist <- as.data.frame(bind_cols(Load)) %>% 
      mutate(
        INDEX = INDEX,
        TaxonKey = Spp
      )
    colnames(sppdist) <- c("SAU_D","Occ","ENM","INDEX","TaxonKey")
    
    #### Step for SAU catch data that has to be averaged
    File_Name <- paste("SAU_data_per_species/CATCH_SP_")
    SppPath <- paste(Distpath,File_Name,Spp,".mat",sep="")
    
    # For now we're using only the last 10 years average, basicaaly if the species has been fished in any of these years, its considered present
    SAU_C_data <- as.data.frame(R.matlab::readMat(SppPath)) %>% 
      select(CATCH.1:CATCH.65) %>% 
      mutate(INDEX = INDEX) %>% 
      gather("Year","Catch",1:10) %>% # Last 10 years of data
      group_by(INDEX) %>% 
      summarise(SAU_C = mean(Catch,na.rm=T))
    
    # Join both tables
    sppdist <- sppdist %>% 
      left_join(SAU_C_data,
                by = "INDEX") %>% 
      select(TaxonKey,INDEX,everything()) %>% 
      left_join(CoorG,
                by = "INDEX")
    
    # Fix coordinate system incompatibility between Gab and DBEM
    sppdist <- suppressWarnings(sppdist[order(sppdist$Latitude, rev(sppdist$Longitude),decreasing=TRUE), ] %>% 
      mutate(INDEX = seq(1,259200,1)) %>% 
      gather("Model","Value",3:6) %>%
      mutate(Value = ifelse(is.na(Value), 0, Value)) # Converting NA's to ceros
    )
    
    getSppDist = sppdist
    
    }else{
      
      # print(paste("No info for this species"))
    }
    
  }else{  
    
    # Merge paths
    SppPath <- paste(Distpath,File_Name,Spp,".mat",sep="")
    
    if(file.exists(SppPath) == TRUE){
      
    #Install (if needed) R.matlab package
    if(!require(R.matlab)){
      install.packages("R.matlab")
    }
    
    # Read Files
    
    sppdist <- as.data.frame(R.matlab::readMat(SppPath)) %>% 
      mutate(INDEX = INDEX,
             Species = Spp) %>% 
      left_join(Coord) 
    
    # Fix coordinate system incompatibility between Gab and DBEM
    sppdist <- sppdist[order(sppdist$Latitude, rev(sppdist$Longitude),decreasing=TRUE), ] %>% 
      mutate(INDEX = seq(1,259200,1))
   
   # Return 
    getSppDist=sppdist
    
    }else{
    print(paste("No info for this species",Spp, "in",Model))
  }
  
  }
}

#______ Test ______#

# Variables outside function
# head(GetSppDist(600004,"SAU_D")) # Works
# head(GetSppDist(600004,"SAU_C")) # Works
# head(GetSppDist(600004,"Occurence")) # Works
# head(GetSppDist(600004,"ENM")) # Works
# head(GetSppDist(600004,"All")) # Works


```

### Function `EstTransIndex`

#### NOTES:

##### General:
- For now using SAU_C as presence absence
- Grouping by species distribution within EEZ and not EEZ area

##### Tresholds:
##### Model Index, line ~479

This first treshold estimates the uncertanty of models. Goes from 0 - 1 as follows:

- 1 or 0; All models agree that in the presence of the species
- 0.75; Three out of four models agree on speices presence
- 0.50; Two out of four models agree on speices presence
- 0.25; Only one model flags a speices presence
- 0; All models agree there is no species there

** NOTE THAT THE FUNCTION IS SETTED TO OUTPUT RESULTS FOR LL MODELS **

##### Distribution Index, line ~482

```{r Trans_Spp_Function, eval= T ,echo = T,warning = F,message = F}

# Function to determine whether or not a species is transboundary

# Varibales needed
# Spp: Species to be analized, data with presence/absence per gridcell
# Index_EEZ: Reference list of all INDEX that fall within EEZs
# EEZ_Size: Number of grid-cells that each EEZ has
# Neighbors: Reference list of neighbouring countries

# Needs getSppDist

#### For testing 
# Spp <- 600059
 #Model <- "All"
 #Neighbors <- Neighbor_List
 #Coord = CoorG
# __________________________________

# The function
EstTransIndex <- function(Spp,Model,Neighbors,Coord,Save="Y"){
  
  # Get model data from spps
  SppDist <- GetSppDist(Spp,Model,Coord)
  
  # Result 1. Number of Countries that share the species
  
  #____________ ESTIMATING MODEL INDEX (TRESHOLD 1)_________ #
  Trans_Spp <- SppDist %>%
    filter(INDEX %in% Neighbors$INDEX,# Filter data only located within EEZs
           Model != "SAU_C") %>% # Only using observational and modelled data
    mutate(Value = ifelse(Value > 0, 1,0)) %>%  
    filter(Value > 0) %>%
    group_by(TaxonKey,
             INDEX
    ) %>%
    summarise(Model_Index = mean(Value,na.rm=T)
    ) %>%
    filter(Model_Index > 0) %>%
    # ____________ ESTIMATING FUNDAMENTAL NICHE (TRESHOLD 2)_________ #
    left_join(SppDist,
              by = c("TaxonKey","INDEX")) %>%
    filter(Model == "SAU_C", # Only keeping cells where SAU catch exists
           Value > 0) %>%
    mutate(Model_Index = Model_Index*100) %>%
    select(-Model, -Value, -Latitude,-Longitude) %>%
    left_join(EEZ_CellID,
              by = "INDEX") %>% 
    left_join(EEZIDs_List,
              by = "EEZID")
  
  # MODEL INDEX (TRESHOLDS 1 & 2) #
  Model_Index_D <- Trans_Spp %>% 
    group_by(Name,
             TaxonKey,
             Model_Index
    ) %>% 
    summarise(n_cells_spp = n()) %>% 
    select(-n_cells_spp)
  
  #____________ ESTIMATING DISTRIBUTION INDEX (TRESHOLD 3)_________ #
  # The number of species' cells present within each country's EEZ
  
  #Step 1.  Get EEZ id and neighbor
  Neighbors_EEZ <- Neighbors %>% 
    group_by(EEZID,Country_Territory,Neighbor_Territory) %>% 
    summarise(n=n()) %>% 
    ungroup() %>% 
    select(-n)
  
  # Step 2. Determines the amount of grids present in each country
  Spp_Grid <- Trans_Spp %>% 
    group_by(TaxonKey,
             Model_Index, # Un-comment after producing models x datasets
             EEZID) %>% 
    summarise(n_spp_eez = length(unique(INDEX))) %>% 
    left_join(Neighbors_EEZ,
              by = "EEZID") %>% 
    filter(Country_Territory %in% Trans_Spp$Name, #Filter out unwanted neighbors (those who don't have grids within but get included because they are neighbors)
           Neighbor_Territory %in% Trans_Spp$Name)
  
  # Step 3. Sum total grids per neighbors
  
  # Split dataframes to merge latter
  Country_Territory_T <- Spp_Grid %>% 
    ungroup() %>% 
    select(
      Model_Index, # Un-comment after producing models x datasets
      TaxonKey,
      Name=Country_Territory,
      n_spp_eez
    )
  
  Neighbor_Territory_T <- Spp_Grid %>% 
    ungroup() %>% 
    select(
      Model_Index,
      TaxonKey,n_spp_eez,
      Name=Neighbor_Territory, 
      Country_Territory
    )
  
  # Merge dataframes to get totals per neighbords
  Area_Index_D <- full_join(Country_Territory_T,
                            Neighbor_Territory_T, 
                            by = c("Model_Index","Name","TaxonKey")
  ) %>%
    rowwise() %>%
    mutate(Spp_Total = sum(n_spp_eez.x,n_spp_eez.y,na.rm=T)) %>% # Total gridcelles per neighbors
    distinct() %>% # Removes false duplicates from `full_join()`
    rename(Neighbor_Territory = Name,
           n_spp_Country = n_spp_eez.x,
           n_spp_Neighbor = n_spp_eez.y) %>% 
    mutate(Area_Index = n_spp_Country/Spp_Total) %>%  #Estimates the proportion of grids per country
    select(1:3,6,8)
  
  #____________ FINAL INDEX TABLE_________ #
  Indexes <- Model_Index_D %>% 
    rename(Country_Territory = Name) %>% 
    full_join(Area_Index_D,
              by = c("TaxonKey","Country_Territory","Model_Index")
    ) %>% 
    filter(!is.na(Area_Index),
           !is.na(Model_Index) # Uncomment after producing Models x datasets
    )%>%  # Remove cases where the country does not pass the area_index and viceversa
    select(TaxonKey,Country_Territory,Neighbor_Territory,everything())
  
  ### Save spp dataframe
  
  if(nrow(Indexes) > 0 & Save == "Y"){
    
    File_Name <- paste(Spp,"_Transboundary.csv",sep = "")
    Save_Path <- paste(Results_Path,File_Name,sep="")
    
    write.csv(Indexes,
              Save_Path,
              row.names = F)
    
  }
  
  if(nrow(Indexes) == 0 & Save == "Y"){
    
    # Reads dataset of Non transboundary species
    Non_Transboundary_Data <- fread(paste(Results_Path,"Non_Transboundary_Data.csv",sep=""))
    
    # Get current Spp that is not transboundary 
    Current_Spp <- tibble(TaxonKey = Spp)
    
    # Combine new spp with others
    New_Non <- Non_Transboundary_Data %>% 
      bind_rows(Current_Spp)
    
    # Set a name for file and saves data
    New_Non_Name <- paste(Results_Path,"Non_Transboundary_Data.csv",sep="")
    write.csv(New_Non, New_Non_Name, row.names = F)
    
  }
  
  ### Function return
  
  EstTransIndex=Indexes # A dataframe with 
  
}
```

```{r Mclapply_Hack_Fun, eval= T , echo = T, warning = F, message = F}

# The hack
# https://www.r-bloggers.com/implementing-mclapply-on-windows-a-primer-on-embarrassingly-parallel-computation-on-multicore-systems-with-r/

Mclapply_Hack <- function(...){
    ## Create a cluster
    size.of.list <- length(list(...)[[1]])

    cl <- makeCluster(min(size.of.list, n_cores))
    
  ## Find out the names of the loaded packages 
    loaded.package.names <- c(
        ## Base packages
        sessionInfo()$basePkgs,
        ## Additional packages
        names(sessionInfo()$otherPkgs))
    tryCatch( {

       ## Copy over all of the objects within scope to
       ## all clusters. 
       this.env <- environment()
       while( identical( this.env, globalenv() ) == FALSE ) {
           clusterExport(cl,
                         ls(all.names=TRUE, env=this.env),
                         envir=this.env)
           this.env <- parent.env(environment())
       }
       clusterExport(cl,
                     ls(all.names=TRUE, env=globalenv()),
                     envir=globalenv())
       
       ## Load the libraries on all the clusters
       ## N.B. length(cl) returns the number of clusters
       parLapply( cl, 1:length(cl), function(xx){
           lapply(loaded.package.names, function(yy) {
               require(yy , character.only=TRUE)})
       })
       
       ## Run the lapply in parallel 
       return( parLapply( cl, ...) )
    }, finally = {        
       ## Stop the cluster
       stopCluster(cl)
    })


## Warn the user if they are using Windows
if( Sys.info()[['sysname']] == 'Windows' ){
    message(paste(
      "\n", 
      "   *** Microsoft Windows detected ***\n",
      "   \n",
      "   For technical reasons, the MS Windows version of mclapply()\n",
      "   is implemented as a serial function instead of a parallel\n",
      "   function.",
      "   \n\n",
      "   As a quick hack, we replace this serial version of mclapply()\n",
      "   with a wrapper to parLapply() for this R session. Please see\n\n",
      "     http://www.stat.cmu.edu/~nmv/2014/07/14/implementing-mclapply-on-windows \n\n",
      "   for details.\n\n"))
}

## If the OS is Windows, set mclapply to the
## the hackish version. Otherwise, leave the
## definition alone. 
mclapply <- switch( Sys.info()[['sysname']],
   Windows = {Mclapply_Hack}, 
   Linux   = {mclapply},
   Darwin  = {mclapply})

}
## end mclapply.hack.R

```


## Routine

```{r Control_Pannel, eval = T, echo = F}

# Removes everything before the number
Step_One <- gsub(".*_","",list.files(paste(Data_Path,"/Distribution_Data/SAU_Distribution/",sep="")))

# Species List
Species_List <- gsub("\\..*","",Step_One)

# Set Spceies list
Exploited_Species <- fread(paste(Data_Path,"Distribution_Data/exploited_species_list.csv",sep="")) %>%
  filter(TaxonKey %in% Species_List)

# Step to run function for species not computed
# Computed_Spp <- as.integer(gsub("\\_.*","",list.files(Results_Path)))

# Exploited_Species <- Exploited_Species %>%
  #filter(!TaxonKey %in% Computed_Spp)

# For Function
Exploited_Species_List <- Exploited_Species$TaxonKey

# Load neighbours data from previouse routine
Neighbor_List <- fread(paste(Data_Path,"Spatial_Data/Neighbor_List.csv", sep =""))

# Gabriel's coordinate system
CoorG <- read.csv(paste(Data_Path,"Spatial_Data/coordinates_gab.csv",sep="")) %>% 
  mutate(INDEX = seq(1,259200,1))

# SAU relations between INDEX and Country's EEZs
EEZIDs_List <- read_excel(paste(Data_Path,"Spatial_Data/V_Lam/Updated_EEZList_17June2016.xlsx",sep=""))
EEZ_CellID <- read_excel(paste(Data_Path,"Spatial_Data/V_Lam/EEZ_CellID.xlsx",sep=""))
colnames(EEZ_CellID) <- c("EEZID","INDEX")

# Creates dummy dataset for Non transboundary species
write.csv(tibble(TaxonKey = "NA"), paste(Results_Path,"Non_Transboundary_Data.csv",sep=""), row.names = F)

# Number of cores to us 
n_cores <- detectCores()-8


####_________________________________________ TESTING PERIOD_________________________________________####
## Species Test Data Just to know what's captured in these countries
#
# SAU_Data <- fread("/Volumes/DATA/JULIANO_NEYMAR/FishForVisa/Distribution_Data/SAU_Catch_Data_Test/SAU_Catch_Data_Test.csv")
# #
# # #### Species per country
# #
# Spps <- SAU_Data %>%
#   filter(data_layer == "Reconstructed domestic catch") %>%
#   group_by(area_name,TaxonName = scientific_name) %>%
#   summarise(n()) %>%
#   left_join(Exploited_Species,
#             by = "TaxonName") %>%
#   filter(TaxonKey %in% Exploited_Species_List$TaxonKey)
#
# Exploited_Species_List <- Spps$TaxonKey

# Exploited_Species_List <- c("600006",600107)
# Exploited_Species_List = 600107
# TaxonKey <- unique(Spps$TaxonKey)


```


```{r Routine_parallel, eval = F, echo = F}

# Spp_Trans <- NULL

system.time(
  Spp_Trans <- bind_rows(
    mclapply(
      Exploited_Species_List, FUN = EstTransIndex, Model = "All", Neighbors = Neighbor_List, Coord = CoorG
    )
  )
)

# Data on time for the Beast with 30 cores
# user   system  elapsed 
 #8117.72  1991.91 10296.00 
    
   
```


# Results

```{r Fun_GetTransResults, eval = F}

GetTransResults=function(Spp){

  # Set the path for each file
  Distpath <- paste(Results_Path,Spp,sep="")
  
  # Loads all files in a df
  Load_Data <- bind_rows(lapply(Distpath, FUN=fread))
  
  return(Load_Data)

}

```

```{r Load_Results_Data, eval = F}

# Spatial Data needed to remove duplicates
sau_eez_fes <- read.csv(paste(Data_Path,"Spatial_Data/sau_eez_fes.csv",sep=""))

Clean_sau_eez_fes <- sau_eez_fes %>% 
  gather("Type","FishingRegion",2,4) %>% 
  left_join(sau_eez_fes,
            by = ("fishing_entity_id")
            ) %>% 
  group_by(FishingRegion,fishing_entity) %>% 
  summarise(n())

# Transboundary Results
Spp <- list.files(Results_Path)[1:675]


Results_Trans <- GetTransResults(Spp)

# Clean out countries that share with their own borders

Clean_Results_Trans <- Results_Trans %>%   
  rename(FishingRegion=Country_Territory) %>% 
  left_join(Clean_sau_eez_fes,
            by = "FishingRegion") %>% 
  select(Model,
         TaxonKey,
         Country_Territory= FishingRegion,
         FishingRegion=Neighbor_Territory,
         Area_Index,
         CT_fishing_entity= fishing_entity) %>% 
  left_join(Clean_sau_eez_fes,
            by = "FishingRegion") %>% 
  select(#1,2, 
    Neighbor_Territory = FishingRegion,
    #Model_Index:CT_fishing_entity,
    NT_fishing_entity= fishing_entity,
    everything()
  ) %>% 
  mutate(
    CT_fishing_entity = ifelse(is.na(CT_fishing_entity),paste(Country_Territory),paste(CT_fishing_entity)),
    NT_fishing_entity = ifelse(is.na(NT_fishing_entity),paste(Neighbor_Territory),paste(NT_fishing_entity)),
    Same_Nation = ifelse(CT_fishing_entity==NT_fishing_entity,"Yes","No")
  )

# For Carmelia
Clean_Results_Trans <- read.csv(paste(Data_Path,"Clean_Results.csv",sep=""))

# Load results for non transboundary (discrete) stocks
Results_Discrete <- fread(paste(Results_Path,"Non_Transboundary_Data.csv",sep=""))

# SAU shapefile

# The path
path_world <- paste(Data_Path,"Spatial_Data/SAU_Shapefile/",sep="")
# #The File
fnam_world <- "SAUEEZ_July2015.shp"
# #Load it!
# 
World_EEZs <- st_read(dsn = path_world,
                      layer =file_path_sans_ext(fnam_world))
# 
# head(World_EEZs)


```


```{r Results_Tresholds, eval =F, echo = F}

TenTwenyfive <- Clean_Results %>% 
  filter(#Model_Index == 100,
         Area_Index >= 0.25,
         Area_Index <= 0.75,
         Same_Nation == "No"
         ) %>% 
  group_by(Name=Country_Territory,Model #,Model_Index
           ) %>% 
  summarise(
    n_trans = length(unique(TaxonKey)),
    n_countries = length(unique(Neighbor_Territory)),
    Trans_Rate = n_trans/n_countries
    ) #%>% 
  # filter(Model_Index == 100)
  # head(Results_Data)

```


## Number of transboundary species per country

```{Tran_country, eval =F, echo =F}

# Number of Transboundary Species
length(unique(Results_Trans$TaxonKey)) #675 spp


# Number of Discret EEZ species
length(unique(Results_Discrete$TaxonKey))


```


```{Tran_country_Map, eval =F, echo =F}




World_EEZs_simple <- World_EEZs %>%
  st_transform(crs = 4326) %>% # 4326
  st_simplify(preserveTopology = TRUE, dTolerance = 0.1) %>%
  left_join(TenTwenyfive, by ="Name") #%>%
  # filter(!is.na(n_trans)) #%>%
  # st_transform(crs = 3832)

# head(World_EEZs_simple)
# World_EEZs_simple %>% 
#   filter(Name == "Chile")

pal <- wes_palette("Zissou1", 1000, type = "continuous")

Plot <- ggplot(World_EEZs_simple) +
  geom_sf(aes(fill = n_trans)) +
  scale_fill_gradientn(colours = pal,
                       na.value = "white") +
  ggtheme_map() +
  facet_wrap(~Model)

ggsave("R4_100_25.png",
       plot = Plot,
       width = 16,
       height = 8,
       units = "in",
       path = "/Volumes/DATA/JULIANO_NEYMAR/FishForVisa/Figures/"
)

```


```{r Circle_Diagram, eval =F, echo = F}

Test_Data <- Clean_Results_Trans %>% 
  rename(FishingRegion=Country_Territory) %>% 
  left_join(Clean_sau_eez_fes,
            by = "FishingRegion") %>% 
  select(TaxonKey,
         Country_Territory= FishingRegion,
         FishingRegion=Neighbor_Territory,
         Model_Index,
         Area_Index,
         CT_fishing_entity= fishing_entity) %>% 
  left_join(Clean_sau_eez_fes,
            by = "FishingRegion") %>% 
  select(1,2, 
    Neighbor_Territory = FishingRegion,
    Model_Index:CT_fishing_entity,
    NT_fishing_entity = fishing_entity,
    everything()
  ) %>% 
  mutate(
    # CT_fishing_entity = ifelse(is.na(CT_fishing_entity),paste(Country_Territory),paste(CT_fishing_entity)),
    # NT_fishing_entity = ifelse(is.na(NT_fishing_entity),paste(Neighbor_Territory),paste(NT_fishing_entity)),
    Same_Nation = ifelse(CT_fishing_entity==NT_fishing_entity,"Yes","No")
  ) %>% 
  filter(Model_Index == 100,
         Area_Index >= 0.25,
         Area_Index <= 0.75,
         Same_Nation == "No"
         ) %>% 
  group_by(from=CT_fishing_entity,
           to = NT_fishing_entity,
           Model_Index
           ) %>% 
  summarise(value = length(unique(TaxonKey))) %>% 
  # filter(from %in% c("Chile","Brazil","Argentina","Peru","Equator")) %>%
  select(from,to,value)


####________________###
# Circulize package ####
####________________###
  
col_mat = rand_color(length(Test_Data), transparency = 0.5)
col_mat[Test_Data < 10] = "#00000000"

chordDiagram(Test_Data, annotationTrack = "grid")

circos.track(track.index = 1, panel.fun = function(x, y) {
    circos.text(CELL_META$xcenter, CELL_META$ylim[1], CELL_META$sector.index, 
        facing = "clockwise", niceFacing = TRUE, adj = c(0, 0.5))
}, bg.border = NA) # here set bg.border to NA is important


```




# Problem solving



### First world Anchovies

In a first run the model suggests anchovies "Engraulis ringens" (600004) is transboundary between US-Mex-Can. I'm exploring this since all four models agree...

Found the probelm, Gab's coordinate system, hecne the data, are in different system than DBEM and SAU data...


```{r Trans_Spp_Function, eval= F ,echo = T,warning = F,message = F}

### DATA EXTRA NEEDED 

# DBEM Coordinate system
Coor <- fread(paste(Data_Path,"Spatial_Data/Lon_Lat_DBEM.txt",sep=""),header = FALSE)
colnames(Coor) <- c("INDEX","Longitude","Latitude")
EEZIDs_List <- read_excel(paste(Data_Path,"Spatial_Data/V_Lam/Updated_EEZList_17June2016.xlsx",sep=""))
EEZ_CellID <- read_excel(paste(Data_Path,"Spatial_Data/V_Lam/EEZ_CellID.xlsx",sep=""))
colnames(EEZ_CellID) <- c("EEZID","INDEX")

CoorG <- read.csv(paste(Data_Path,"Spatial_Data/coordinates_gab.csv",sep="")) %>% 
  mutate(INDEX = seq(1,259200,1))

# colnames(CoorG) <- c("INDEX","Longitude","Latitude")
coords <- CoorG[order(CoorG$Latitude, rev(CoorG$Longitude),decreasing=TRUE), ] 

# Explore model step by step

# Get Catch Data
Anchoveta_Dist <- GetSppDist(600004,"All",CoorG)


Anchoveta_Dist_Coor <- Anchoveta_Dist %>% 
  left_join(CoorG)

# Swap coordinate system to match DBEM and SAU
Anchoveta_Dist_Coor_Fix <- Anchoveta_Dist_Coor[order(Anchoveta_Dist_Coor$Latitude, rev(Anchoveta_Dist_Coor$Longitude),decreasing=TRUE), ] 


x <- Anchoveta_Dist %>% 
  left_join(EEZ_CellID) %>% 
  left_join(EEZIDs_List) %>% 
  filter(
    # Model == "Occ",
    Value >0)


# head(x)
# Exploring using Vicky's data

ggplot(x) +
  geom_tile(aes(
    x = Longitude,
    y = Latitude,
    fill = Name,
    color = Name
  )
  ) +
  facet_wrap(~Model)


Spp_Trans <- bind_rows(
    mclapply(
      600004, FUN =EstTransIndex, Model = "All", Neighbors = Neighbor_List, Coord = CoorG
    )
  )


  # Estimate total spp distribution within neighbours
  
  Trans_Spp <- SppDist %>%
    filter(INDEX %in% Neighbors$INDEX) %>% # Filter data only located within EEZs
    mutate(Value = ifelse(Value > 0, 1,0)) %>%  # For now using SAU_C as presence absence
    group_by(TaxonKey,
             INDEX
    ) %>%
    summarise(Model_Index = mean(Value,na.rm=T)) %>%
    filter(Model_Index > 0) %>%
    mutate(Model_Index = Model_Index*100) %>%
    left_join(Neighbors,
              by = "INDEX")
    
    Test <- Trans_Spp %>% 
      filter(Name == "USA (West Coast)" & Model_Index ==100)


 # Explore only SAU catch data

# Get Catch Data
Anchoveta_Dist <- GetSppDist(Spp,"SAU_C")
    
# Get Mex, Can and USA W coast Grid
Anchoveta_Dist_EEZ <- Anchoveta_Dist %>% 
  

Anchoveta_NA <-  Anchoveta_Dist%>% 
  filter(INDEX %in% North_America$INDEX) %>% 
  gather("Year","Tonnes",CATCH.1:CATCH.65) %>% 
  group_by(Year) %>% 
  summarise(Sum_T = sum(Tonnes, na.rm =T))



```


#### Overcounting transboundary stocks

In a first run, Australia results in many transboundary stocks, I believe this is because it is counting the number of countries that that the species share (e.g. one species 6 countries = 6 transboundary spp) rather than 1 speces 6 countries = 1 trans spp.

**Problem fixed.** Now we can estimate the number of transboundary species as well as the number of countries/regions that each country shares per species.

```{Australia_case, eval =F, echo = F}

Australia <- Results_Data %>% 
  filter(Name == "Australia")

Original_Australia <-Australia %>% 
  filter(Model_Index >= 50#,
         # Trans_Index >= 0.10
         ) %>% 
  group_by(Name,Model_Index) %>% 
  summarise(n_Trans_Spp = n()) %>% 
  filter(Model_Index == 100)

## Testing the waters

Explore_Australia <- Australia %>% 
  filter(Model_Index >= 50#,
         # Trans_Index >= 0.10
         ) %>% 
  slice(1:20) %>% 
  group_by(Name,Model_Index) %>% 
  summarise(
    n_trans = length(unique(TaxonKey)),
    n_countries = length(unique(Neighbor_Territory)),
    )

```

#### Fixing counts within EEZs

In the first run. Countries where EEZs are devided but touching (e.g. South Africa inidan and atlantic coasts) are double counted.

This might be fixed with Tayler's data of EEZs to ISOs... He did it manually so it does not work! 

```{South_Africa_case, eval =F, echo = F}

# Tyler E.'s' data
EEZ_ISO <- read.csv("/Volumes/DATA/JULIANO_NEYMAR/FishForVisa/Spatial_Data/EEZID_ISO_TylEd.csv", comment.char="#")

#SAU / Vicky's data
EEZIDs_List <- read_excel(paste(Data_Path,"Spatial_Data/V_Lam/Updated_EEZList_17June2016.xlsx",sep=""))

EEZ_CellID <- read_excel(paste(Data_Path,"Spatial_Data/V_Lam/EEZ_CellID.xlsx",sep=""))
colnames(EEZ_CellID) <- c("EEZID","INDEX")

# Worlds adata

# The path
path_world <- paste(Data_Path,"Spatial_Data/World_EEZ_v10_2018",sep="")
# #The File
fnam_world <- "eez_v10.shp"
# #Load it!
# 
World_EEZs <- st_read(dsn = path_world,
                      layer =file_path_sans_ext(fnam_world))

head(World_EEZs)

World_EEZs %>% 
  filter(
    # Territory1 == "South Africa",
    ISO_Ter1 == "ZAF") %>% 
  head()

# Get ISO and territory names from world map
ISO_Ter <- World_EEZs %>%
  select(ISO_Ter1,Territory1) %>% 
  as.data.frame() %>% 
  select(ISO_Ter1,Territory1)

head(ISO_Ter)

# I think EEZID equals ISO when not devided... 

EZZID_Yes_ISO <- ISO_Ter %>% 
  semi_join(ISO_Ter,
            by ="ISO_Ter1") %>% 
  rename(Name = Territory1) %>% 
  # head() %>% 
  left_join(EEZIDs_List,
            by = "Name")


EEZ_ISO_Clean <- ISO_Ter %>% 
  left_join(EEZ_ISO,
            by = "ISO_Ter1")

SA <- Results_Data %>% 
  filter(stringr::str_detect(Name,"South Africa"))


## Creating a subset dataset so i can work on my laptop and not remoteley

SubsetData <- Clean_Results %>% 
  filter(Country_Territory=="USA (East Coast)")

write.csv(SubsetData,
          "SubsetData.csv",
          row.names = F) # Using USA East coast and Gulf as example

###_____________________________ ###

# Loading subsetted data

Clean_Results <- read.csv("~/GitHub/FishForVisa/Temporal_Data/SubsetData.csv")

sau_eez_fes <- read.csv("~/GitHub/FishForVisa/Temporal_Data/sau_eez_fes.csv")
  

Neighbord_Territory_T <- Clean_Results %>% 
  group_by(eez_name=Neighbor_Territory) %>% 
  summarise() %>%
  left_join(sau_eez_fes,
            by = "eez_name") %>% 
  select(Neighbor_Territory= eez_name,
         NT_fishing_entity=fishing_entity
         )

Country_Territory_T <- Clean_Results %>% 
  group_by(eez_name=Country_Territory) %>% 
  summarise() %>%
  left_join(sau_eez_fes,
            by = "eez_name")  %>% 
  select(Country_Territory= eez_name,
         CT_fishing_entity=fishing_entity)

Non_duplicate_Data <- Clean_Results %>%   
  left_join(Neighbord_Territory_T,
              by ="Neighbor_Territory") %>% 
  left_join(Country_Territory_T,
              by ="Country_Territory") %>% 
  mutate(
    Same_Nation = ifelse(CT_fishing_entity==NT_fishing_entity,"Yes","No")
  ) %>% 
  filter(Same_Nation == "No")


# FIXED!!!!! 

```

- **Done debugging**

#### Missing stocks

There are places like Peru-Chile or Alaska-Canada that should have trans spp... In Alaska the issue is that Alaska doesn't actually exist as a separate shapefile...

```{r Missing_stocks, eval =F}

Exploited_Species <- fread(paste(Data_Path,"Distribution_Data/exploited_species_list.csv",sep=""))

Clean_sau_eez_fes <- sau_eez_fes %>% 
  gather("Type","FishingRegion",2,4) %>% 
  left_join(sau_eez_fes,
            by = ("fishing_entity_id")
            ) %>% 
  group_by(FishingRegion,fishing_entity) %>% 
  summarise(n())


# The Alaska paradox
# It's a problem of the NAs, fixed.

USA_West <- Results_Data %>% 
  filter(Country_Territory == "USA (West Coast)") %>% 
  left_join(Exploited_Species,
            by = "TaxonKey")

# Northern sea Russia
Russia_map <- World_EEZs %>% 
  filter(stringr::str_detect(Name,"Russia")) %>% 
  st_simplify(preserveTopology = TRUE, dTolerance = 100) 

head(Russia_map)

ggplot(Russia_map) +
  geom_sf(aes(fill = Name)) 
# Shapefiles not matching
# Russia (Laptev to Chukchi Sea)
# Russia (Kara Sea)

Russian_Regions <- c("Russia (Laptev to Chukchi Sea)","Russia (Kara Sea)")

Russia_Results <- Results_Data %>% 
  filter(stringr::str_detect(Country_Territory,"Russia"))
  
unique(Russia_Results$Country_Territory)
# Missing Laptev to Chukchi sea

### What about Vicky's data
#SAU / Vicky's data
EEZIDs_List <- read_excel(paste(Data_Path,"Spatial_Data/V_Lam/Updated_EEZList_17June2016.xlsx",sep=""))

Russia_EEZlist <- EEZIDs_List %>% 
  filter(stringr::str_detect(Name,"Russia"))
  
unique(Russia_EEZlist$Name)

### So maybe there are no neighbors?
Neighbor_List <- fread(paste(Data_Path,"Spatial_Data/Neighbor_List.csv", sep =""))

Russia_Neighbor <- Neighbor_List %>% 
  filter(stringr::str_detect(Name,"Russia"))
  
unique(Russia_Neighbor$Country_Territory)

# OK So Kara Sea has no borders outside Russia, hence white. Now Laptev does have borders but No species... which is weird... Paific Halibut?

# I manually ran the function to see what's going on

# ggplot() +
#   geom_sf(data = Russia_map, aes(colour = Name)) +
#   geom_tile(data = subset(SppDist, Value !=0),
#             aes(
#     x = Longitude,
#     y = Latitude,
#     fill = log10(Value)
#   ) 
#   ) +
#   facet_wrap(~Model)

# The main issue is that there is no catch data there...

```


# Extra Analysis

## Extra Analysis; Functions

```{r Trans_Spp_Function_All, eval = F ,echo = T,warning = F,message = F}

# Function to determine whether or not a species is transboundary for each model

# Varibales needed
# Spp: Species to be analized, data with presence/absence per gridcell
# Index_EEZ: Reference list of all INDEX that fall within EEZs
# EEZ_Size: Number of grid-cells that each EEZ has
# Neighbors: Reference list of neighbouring countries

# Needs getSppDist

#### For testing 
# Spp <- 600059
# Model <- "All"
# Neighbors <- Neighbor_List
# Coord = CoorG
# __________________________________

# The function
EstTransIndex <- function(Spp,Model,Neighbors,Coord,Save="Y"){
  
  # Get model data from spps
  SppDist <- GetSppDist(Spp,Model,Coord)
  
  # Result 1. Number of Countries that share the species
  
  #____________ ESTIMATING MODEL INDEX (TRESHOLD 1)_________ #
  Trans_Spp <- SppDist %>%
    filter(INDEX %in% Neighbors$INDEX,# Filter data only located within EEZs
           Model != "SAU_C") %>% # Only using observational and modelled data
    mutate(Value = ifelse(Value > 0, 1,0)) %>%
    left_join(EEZ_CellID,
              by = "INDEX") %>% 
    left_join(EEZIDs_List,
              by = "EEZID")
  
  # MODEL INDEX (TRESHOLDS 1 & 2) #
  Model_Index_D <- Trans_Spp %>% 
    group_by(Name,
             TaxonKey,
             Model
    ) %>% 
    summarise(n_cells_spp = n()) %>% 
    select(-n_cells_spp)
  
    #____________ ESTIMATING DISTRIBUTION INDEX (TRESHOLD 3)_________ #
   # The number of species' cells present within each country's EEZ
  
  #Step 1.  Get EEZ id and neighbor
  Neighbors_EEZ <- Neighbors %>% 
  group_by(EEZID,Country_Territory,Neighbor_Territory) %>% 
  summarise(n=n()) %>% 
  ungroup() %>% 
  select(-n)

  # Step 2. Determines the amount of grids present in each country
  Spp_Grid <- Trans_Spp %>% 
    group_by(TaxonKey,
             Model, 
             EEZID) %>% 
    summarise(n_spp_eez = length(unique(INDEX))) %>% 
    left_join(Neighbors_EEZ,
              by = "EEZID") %>% 
    filter(Country_Territory %in% Trans_Spp$Name, #Filter out unwanted neighbors (those who don't have grids within but get included because they are neighbors)
           Neighbor_Territory %in% Trans_Spp$Name)
  
  # Step 3. Sum total grids per neighbors
  
  # Split dataframes to merge latter
  Country_Territory_T <- Spp_Grid %>% 
    ungroup() %>% 
    select(
      Model_Index, # Un-comment after producing models x datasets
      TaxonKey,Name=Country_Territory,n_spp_eez
    )
  
  Neighbor_Territory_T <- Spp_Grid %>% 
    ungroup() %>% 
    select(
      Model_Index,
      TaxonKey,n_spp_eez,Name=Neighbor_Territory, Country_Territory
    )

  # Merge dataframes to get totals per neighbords
  Area_Index_D <- full_join(Country_Territory_T,
                           Neighbor_Territory_T, by = c("Name","TaxonKey","Model")) %>%
    rowwise() %>%
    mutate(Spp_Total = sum(n_spp_eez.x,n_spp_eez.y,na.rm=T)) %>% # Total gridcelles per neighbors
    distinct() %>% # Removes false duplicates from `full_join()`
    rename(Neighbor_Territory = Name,
           n_spp_Country = n_spp_eez.x,
           n_spp_Neighbor = n_spp_eez.y) %>% 
    mutate(Area_Index = n_spp_Country/Spp_Total) %>%  #Estimates the proportion of grids per country
    select(1:4,6,8)

  #____________ FINAL INDEX TABLE_________ #
  Indexes <- Model_Index_D %>% 
  rename(Country_Territory = Name) %>% 
  full_join(Area_Index_D,
            by = c("TaxonKey","Country_Territory","Model")
  ) %>% 
    filter(!is.na(Area_Index))%>%  # Remove cases where the country does not pass the area_index and viceversa
    select(Model,TaxonKey,Country_Territory,Neighbor_Territory,everything())

  ### Save spp dataframe
  
  if(nrow(Indexes) > 0 & Save == "Y"){
    
    File_Name <- paste(Spp,"_Transboundary.csv",sep = "")
    Save_Path <- paste(Results_Path,"All_Models/",File_Name,sep="")
    
    write.csv(Indexes,
              Save_Path,
              row.names = F)
    
  }
  
  if(nrow(Indexes) == 0 & Save == "Y"){
    
# Reads dataset of Non transboundary species
    Non_Transboundary_Data <- fread(paste(Results_Path,"All_Models/","Non_Transboundary_Data.csv",sep=""))
    
    # Get current Spp that is not transboundary 
    Current_Spp <- tibble(Non_trans = Spp)
    
    # Combine new spp with others
    New_Non <- Non_Transboundary_Data %>% 
      bind_rows(Current_Spp)
    
    # Set a name for file and saves data
    New_Non_Name <- paste(Results_Path,"All_Models/","Non_Transboundary_Data.csv",sep="")
    write.csv(New_Non, New_Non_Name, row.names = F)
    
  }
  
  ### Function return
  
  EstTransIndex=Indexes # A dataframe with 
  
}


### Testing Function ####
# Spp <- 600006
# Model <- "All"
# Neighbors <- Neighbor_List
# 
# Tryout <- EstTransIndex(Spp,Model,Neighbors,CoorG,Save="N")
# 
# Over_20 <-Tryout %>% 
#     filter(Area_Index > 0.20,
#            Area_Index < 0.80)
  
# Spp <- NULL
# Model <- NULL

```

## Extra Analysis; Results

```{Tran_country_Map_All, eval =F, echo =F}

World_EEZs_simple <- World_EEZs %>%
  st_transform(crs = 4326) %>% # 4326
  st_simplify(preserveTopology = TRUE, dTolerance = 0.1) %>%
  left_join(TenTwenyfive, by ="Name") #%>%
  # filter(!is.na(n_trans)) #%>%
  # st_transform(crs = 3832)

# head(World_EEZs_simple)
# World_EEZs_simple %>% 
#   filter(Name == "Chile")

pal <- wes_palette("Zissou1", 100, type = "continuous")

Mod <- unique(TenTwenyfive$Model)

# Loop through all variables
for(v in 1:length(Mod)){
  
  Model_List <- Mod[v]
  
  plot <- ggplot(data = subset(World_EEZs_simple,Model %in% Model_List)) +
    geom_sf(aes(fill = n_trans)) +
    scale_fill_gradientn(colours = pal,
                         na.value = "white") +
    ggtheme_map() +
    ggtitle(paste(Model_List))
  
  # Name plot
  Plot_Name <- paste(Model_List,"plot.png",sep="_")
  
  # Save plot
  ggsave(
    plot = plot,
    width = 14,
    height = 10,
    units = "in",
    filename = Plot_Name,
    path = "/Volumes/DATA/JULIANO_NEYMAR/FishForVisa/Figures/All_Models/"
  )
    
  }

```
